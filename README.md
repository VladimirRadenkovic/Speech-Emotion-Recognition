# Speech-Emotion-Recognition using Convolutional Neural Networks
## Table of contents
* [Project Description](#project-description)
* [Feature Extraction](#feature-extraction)
* [Data Augmentation](#data-augmentation)
* [Model Architecture](#model-architecture)
* [Hyperparameter Tuning](#hyperparameter-tuning)
* [Results](#results)

## Project Description
The aim of this project is to build Convolutional Neural Network for speech emotion classification.
Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech. This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon that animals like dogs and horses employ to be able to understand human emotion. 
Datasets used in this project are:
* Crowd-sourced Emotional Mutimodal Actors Dataset (Crema-D)
* Ryerson Audio-Visual Database of Emotional Speech and Song (Ravdess)
* Surrey Audio-Visual Expressed Emotion (Savee)
* Toronto emotional speech set (Tess)
For this project I used following libraries: librosa, keras, sklearn, matplotlib, seaborn, numpy, pandas, pickle, itertools
